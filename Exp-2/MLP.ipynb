{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e57dd269-88c5-4b4b-81b0-6dae15a58005",
   "metadata": {},
   "source": [
    "Objective: \n",
    "Write a program to implement a multi-layer perceptron (MLP) network with one hidden layer using numpy in Python. Demonstrate that it can learn the XOR Boolean function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f75b04-7b16-4eb1-afa9-5427b2dd4449",
   "metadata": {},
   "source": [
    "Description of Model:\n",
    "This model uses a single-layer perceptron network for binary classification of logic functions. Four perceptrons learn different logic functions, and their outputs serve as inputs to a final perceptron, which classifies a new function.\n",
    "\n",
    "ðŸ”¹ Model Structure\n",
    "Input Layer: Takes two binary inputs.\n",
    "Intermediate Perceptrons: Learn different logic functions.\n",
    "Final Perceptron: Uses learned outputs to classify a new function.\n",
    "ðŸ”¹ Training & Learning\n",
    "Weights update via the Perceptron Learning Rule over multiple epochs.\n",
    "The final perceptron refines classification using predictions from the previous perceptrons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44cfebc8-720b-473c-b141-522cfd4b399b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Perceptron Accuracy: 100.00% | Predictions: [0 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Perceptron class for binary classification\n",
    "class Perceptron:\n",
    "    def __init__(self, input_size, learning_rate=0.1, epochs=25):\n",
    "        \"\"\"\n",
    "        Initialize the perceptron with random weights, learning rate, and number of epochs.\n",
    "\n",
    "        Parameters:\n",
    "        input_size (int): Number of input features.\n",
    "        learning_rate (float): Step size for weight updates.\n",
    "        epochs (int): Number of training iterations.\n",
    "        \"\"\"\n",
    "        self.weights = np.random.randn(input_size + 1)  # Including bias term\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "\n",
    "    def activation(self, x):\n",
    "        \"\"\"Activation function: Returns 1 if x >= 0, otherwise 0.\"\"\"\n",
    "        return 1 if x >= 0 else 0\n",
    "\n",
    "    def predict(self, x):\n",
    "        \"\"\"Predicts the output for a given input.\"\"\"\n",
    "        x_with_bias = np.insert(x, 0, 1)  # Add bias term at the beginning\n",
    "        return self.activation(np.dot(self.weights, x_with_bias))\n",
    "\n",
    "    def train(self, X, y):\n",
    "        \"\"\"\n",
    "        Train the perceptron using the perceptron learning rule.\n",
    "\n",
    "        Parameters:\n",
    "        X (ndarray): Training data inputs.\n",
    "        y (ndarray): Training data outputs.\n",
    "        \"\"\"\n",
    "        X_bias = np.c_[np.ones(X.shape[0]), X]  # Add bias column\n",
    "        for _ in range(self.epochs):\n",
    "            for i in range(X.shape[0]):  \n",
    "                prediction = self.activation(np.dot(self.weights, X_bias[i]))  \n",
    "                # Update weights using the perceptron learning rule\n",
    "                self.weights += self.learning_rate * (y[i] - prediction) * X_bias[i]\n",
    "\n",
    "    def evaluate(self, X, y):\n",
    "        \"\"\"\n",
    "        Evaluate the perceptron performance.\n",
    "\n",
    "        Parameters:\n",
    "        X (ndarray): Input data.\n",
    "        y (ndarray): True labels.\n",
    "\n",
    "        Returns:\n",
    "        tuple: Accuracy percentage and predictions.\n",
    "        \"\"\"\n",
    "        predictions = np.array([self.predict(x) for x in X])\n",
    "        accuracy = np.mean(predictions == y) * 100\n",
    "        return accuracy, predictions\n",
    "\n",
    "# Function to Train and Evaluate the Perceptron\n",
    "def train_perceptron(X, y, label, final=False):\n",
    "    \"\"\"\n",
    "    Trains the perceptron and evaluates its performance.\n",
    "\n",
    "    Parameters:\n",
    "    X (ndarray): Input data.\n",
    "    y (ndarray): Target labels.\n",
    "    label (str): Label for identification.\n",
    "    final (bool): If True, print the accuracy (only for final perceptron).\n",
    "\n",
    "    Returns:\n",
    "    tuple: Predictions and actual target labels.\n",
    "    \"\"\"\n",
    "    perceptron = Perceptron(input_size=X.shape[1])\n",
    "    perceptron.train(X, y)\n",
    "    accuracy, predictions = perceptron.evaluate(X, y)\n",
    "\n",
    "    if final:  # Print accuracy only for the final perceptron\n",
    "        print(f\"{label} Accuracy: {accuracy:.2f}% | Predictions: {predictions}\")\n",
    "\n",
    "    return predictions, y\n",
    "\n",
    "# Truth table inputs (X values)\n",
    "X_values = np.array([\n",
    "    [0, 0],\n",
    "    [0, 1],\n",
    "    [1, 0],\n",
    "    [1, 1]\n",
    "])\n",
    "\n",
    "# Truth table outputs (Y values) for different logic functions\n",
    "Y_fun1 = np.array([0, 0, 0, 1])  # NAND function\n",
    "Y_fun2 = np.array([0, 0, 1, 0])  # Custom function\n",
    "Y_fun3 = np.array([0, 1, 0, 0])  # Custom function\n",
    "Y_fun4 = np.array([1, 0, 0, 0])  # Custom function\n",
    "\n",
    "# Train perceptrons for each individual function (without printing accuracy)\n",
    "pred_1, _ = train_perceptron(X_values, Y_fun1, \"Fun1\")\n",
    "pred_2, _ = train_perceptron(X_values, Y_fun2, \"Fun2\")\n",
    "pred_3, _ = train_perceptron(X_values, Y_fun3, \"Fun3\")\n",
    "pred_4, _ = train_perceptron(X_values, Y_fun4, \"Fun4\")\n",
    "\n",
    "# Combine predictions from previous perceptrons as input for the final perceptron\n",
    "final_input = np.column_stack([pred_1, pred_2, pred_3, pred_4])\n",
    "final_output = np.array([0, 1, 1, 0])  # Desired final output\n",
    "\n",
    "# Train and evaluate the final perceptron (Printing only final accuracy)\n",
    "final_predictions, actual_y = train_perceptron(final_input, final_output, \"Final Perceptron\", final=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac91667d-7d01-4385-b6ca-2ee86bbf5216",
   "metadata": {},
   "source": [
    "This program implements a single-layer perceptron to learn and classify logical functions. Multiple perceptrons are trained on different truth table outputs, and their predictions are combined as inputs for a final perceptron, which learns a new function.\n",
    "\n",
    "Key Components:\n",
    "âœ… Perceptron Class â€“ Implements binary classification using the Perceptron Learning Rule.\n",
    "âœ… Training Function â€“ Trains perceptrons on logic functions and returns predictions.\n",
    "âœ… Truth Table Inputs â€“ Defines input (X_values) and multiple logic function outputs.\n",
    "âœ… Final Perceptron â€“ Uses predictions from previous perceptrons to learn a new function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0929afb4-07d6-4743-b6fc-81cf2263f83d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
